{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Guide to Data\n\nA notebook guide to working with PUNCH FITS files in Python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This Jupyter Notebook presents a comprehensive guide to the analysis and visualization of PUNCH FITS files using Python. The guide leverages a suite of Python libraries, including `matplotlib` for data visualization, numpy for numerical operations, `astropy` for FITS file handling and WCS manipulation, `sunpy` for solar data analysis, and `ndcube` for multi-dimensional data handling. The notebook serves as a robust resource for researchers and scientists, providing them with the tools and knowledge to effectively manipulate and interpret PUNCH FITS files. The guide's step-by-step approach, coupled with code snippets and detailed explanations, ensures a user-friendly experience, promoting the accessibility of PUNCH data for a wider scientific community.\n\nTo install these dependencies, use `pip install -r requirements.txt` in your terminal.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load libraries\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n\nimport astropy.units as u\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom astropy.io import fits\nfrom astropy.wcs import WCS\nfrom matplotlib.colors import LogNorm\nfrom ndcube import NDCube\nfrom sunpy.map import Map\n\nfrom punchbowl.data.sample import PUNCH_PAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading\n\nWe first specify the file we wish to load. For this notebook, let's use the included L3 PAM file. Then, we'll load it two different ways:\n\n1. With `astropy.io`\n2. With `SunPy Maps`\n\nThe data are RICE compressed, so we'll have to look in the *second* at index 1 (since we're zero-indexed) HDU for the main data frame.\nThere is also an uncertainty layer in the last HDU that we'll explore later.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with fits.open(PUNCH_PAM) as hdul:\n    data = hdul[1].data\n    header = hdul[1].header\n    uncertainty = hdul[2].data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's look at the shape of the data. For this data product, total brightness and polarized brightness are stacked along the first dimension.\nThe uncertainty array corresponds on a pixel-to-pixel basis with the data array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(data.shape, uncertainty.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can look in the header for details about the data. A few things to note:\n\n- The header is divided into helpful sections such as \"temporal information\" and \"instrument and spacecraft state.\" This aids in navigating the information. These sections are consistent for other products (with the addition of more sections depending on the product).\n- There are two world coordinate systems (WCS), one for the helio system and one for a celestial right ascension and declination system. They match each other and can be used interchangeably depending on the type of analysis.\n- The first dimension iterates over total brightness and polarized brightness, in that order. This is indicated by the `OBSLAYR1` and `OBSLAYR2` keywords.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(header)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can create `Astropy WCS` objects from the header. Since the data are three dimensional, the WCS will be three dimensions. Luckily, we can slice WCSes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_wcs = WCS(header)\nprint(data_wcs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also access the celestial WCS by setting `key='A'`. \"\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_wcs_celestial = WCS(header, key=\"A\")\nprint(data_wcs_celestial)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also use SunPy Maps to load the data. However, since Maps only support 2D images, it will warn us that it's truncating a dimension of the data and only showing the total brightness. We get a list of Maps where the first entry is the data and the second is the uncertainty.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_map = Map(PUNCH_PAM)\ndata_map[0].plot()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you wish to make a map of the polarized brightness, we can also do that manually.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_map = Map(data[1], header)\ndata_map.plot()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting data\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are many ways to plot the data. We are working on more visualization tools that will be available with the release of the `punchbowl` package. First, we can plot the SunPy map.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_map.plot(norm=\"log\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also use Matplotlib directly to modify the plot however we want. Notice that we set the projection so it is coordinate aware. Remember we have to slice the WCS as `data_wcs[0]` instead of `data_wcs` because our data are 3D but we want to view only the spatial dimensions.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the data using matplotlib manually\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(9.5, 7.5), subplot_kw={\"projection\":data_wcs[0]})\n\nim = ax.imshow(data[1], cmap=\"Greys_r\", norm=LogNorm(vmin=1.77e-15, vmax=3.7e-11))\n\n# set up the axis labels\nlon, lat = ax.coords\nlat.set_ticks(np.arange(-90, 90, 15) * u.degree)\nlon.set_ticks(np.arange(-180, 180, 15) * u.degree)\nlat.set_major_formatter(\"dd\")\nlon.set_major_formatter(\"dd\")\nax.set_facecolor(\"black\")\nax.coords.grid(color=\"white\", alpha=.25, ls=\"dotted\")\nax.set_xlabel(\"Helioprojective longitude\")\nax.set_ylabel(\"Helioprojective latitude\")\nax.set_title(\"Synthetic PUNCH Polarized Brightness\")\nfig.colorbar(im, ax=ax, label=\"Mean Solar Brightness\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we set the projection, we could also use the celestial WCS instead.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the data using matplotlib manually, using the celestial frame\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(9.5, 7.5), subplot_kw={\"projection\":data_wcs_celestial[0]})\n\nim = ax.imshow(data[0], cmap=\"Greys_r\", norm=LogNorm(vmin=1.77e-15, vmax=3.7e-11))\n\n# set up the axis labels\nlon, lat = ax.coords\nlat.set_ticks(np.arange(-90, 90, 15) * u.degree)\nlon.set_ticks(np.arange(-180, 180, 15) * u.degree)\nlat.set_major_formatter(\"dd\")\nlon.set_major_formatter(\"dd\")\nax.set_facecolor(\"black\")\nax.coords.grid(color=\"white\", alpha=.25, ls=\"dotted\")\nax.set_xlabel(\"RA\")\nax.set_ylabel(\"DEC\")\nax.set_title(\"Synthetic PUNCH Polarized Brightness\")\nfig.colorbar(im, ax=ax, label=\"Mean Solar Brightness\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reprojecting the data\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What if we want want to manipulate the images? We can use built-in tools of SunPy Maps. For example, we can reproject.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What if we wanted to reproject the data to a new arbitrary coordinate frame?\nFirst, define a new target WCS\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "new_wcs = deepcopy(data_map.wcs)\nnew_wcs.wcs.ctype = \"HPLN-ARC\", \"HPLT-ARC\"\nnew_wcs.wcs.cunit = \"deg\", \"deg\"\nnew_wcs.array_shape = 1024, 1024\nnew_wcs.wcs.crpix = 512, 512\nnew_wcs.wcs.crval = 10, 10\nnew_wcs.wcs.cdelt = 0.0225, 0.0225\nnew_wcs.wcs.pc = (0.66,-0.33), (0.33,0.66)\n\n# We can then reproject using SunPy maps\nnew_map = data_map.reproject_to(new_wcs)\nnew_map.plot()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using NDCube\n\nSo far, we've only talked about directly manipulating the data or using SunPy Maps. However, we encourage you to utilize NDCubes. We use them in the data reduction pipeline too. [NDCube](https://docs.sunpy.org/projects/ndcube/en/stable/introduction.html) is a SunPy package for generalized n-dimensional data. We can use our manually loaded data to make an NDCube with all of the data in one place. There's even a way to bundle uncertainty directly into the cube.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_ndcube = NDCube(data, wcs=data_wcs, meta=header, uncertainty=uncertainty)\nprint(data_ndcube)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then use all the great NDCube functionality! Much like SunPy Maps we can reproject even. Note that as of writing this guide, the uncertainty is dropped when NDCube reprojects data.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "make a target WCS\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "new_wcs = deepcopy(data_wcs)\nnew_wcs.wcs.ctype = \"HPLN-ARC\", \"HPLT-ARC\", \"STOKES\"\nnew_wcs.wcs.cunit = \"deg\", \"deg\", \"\"\nnew_wcs.array_shape = 2, 1024, 1024\nnew_wcs.wcs.crpix = 0, 0, 0\nnew_wcs.wcs.crval = 0, 0, 0\nnew_wcs.wcs.cdelt = 0.0225, 0.0225, 1.0\n\nnew_cube = data_ndcube.reproject_to(new_wcs)\nnew_cube.plot()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NDCubes have a plotter on them too. Notice we even get an interactive slider to manipulate the polarization axis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "new_cube.plot(interpolation=\"None\", norm=LogNorm(vmin=1.77E-15, vmax=3.7E-11), cmap=\"Greys_r\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We encourage you to explore NDCube more. There are other helpful things like [cropping](https://docs.sunpy.org/projects/ndcube/en/stable/generated/gallery/slicing_ndcube.html#cropping-cube-using-world-coordinate-values-using-ndcube-ndcube-crop) that you can do.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uncertainty\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Level 1, 2, and 3 PUNCH products come with an uncertainty estimate. This uncertainty is expressed as the fractional uncertainty ranging from 0 to 1. To get the absolute uncertainty, simply multiply the fractional uncertainty by the data value.\n\nThere's an extra step though. Uncertainty is encoded as an integer in the FITS file to save space. When we inspect the uncertainty, we see it ranges from 0 to 255. Here, 255 corresponds to a fractional uncertainty of 1.0 or complete uncertainty.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(uncertainty.min(), uncertainty.max())  # values range from 0 to 255\n\nabsolute_uncertainty = uncertainty.astype(float) / 255 * data\nprint(absolute_uncertainty.min(), absolute_uncertainty.max())  # now the uncertainty is in the same units as the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the data and uncertainty to get a feel for it. As mentioned earlier, analysis and visualization tools that make this easier will be released with the `punchbowl` package.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vmin, vmax = 1.77E-15, 3.7E-11\n\nfig, axs = plt.subplots(figsize=(14, 6), ncols=2, subplot_kw={\"projection\":data_wcs[0]})\n\nim = axs[0].imshow(data[0], norm=LogNorm(vmin=vmin, vmax=vmax), interpolation=\"None\", cmap=\"Greys_r\")\naxs[0].set_title(\"Data\")\n\naxs[1].imshow(absolute_uncertainty[0], norm=LogNorm(vmin=vmin, vmax=vmax), interpolation=\"None\", cmap=\"Greys_r\")\naxs[1].set_title(\"Uncertainty\")\n\nfig.colorbar(im, ax=axs, label=\"Mean Solar Brightness\")\n\n# set up the axis labels\nfor ax in axs:\n    lon, lat = ax.coords\n    lat.set_ticks(np.arange(-90, 90, 15) * u.degree)\n    lon.set_ticks(np.arange(-180, 180, 15) * u.degree)\n    lat.set_major_formatter(\"dd\")\n    lon.set_major_formatter(\"dd\")\n    ax.set_facecolor(\"black\")\n    ax.coords.grid(color=\"white\", alpha=.25, ls=\"dotted\")\n    ax.set_xlabel(\"Helioprojective longitude\")\n    ax.set_ylabel(\"Helioprojective latitude\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}